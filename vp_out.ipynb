{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9254, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 데이터 불러오기 및 전처리\n",
    "df1 = pd.read_csv('data/교통사고 데이터/전국교통사고다발지역(2012-2021).csv', encoding='euc-kr')\n",
    "# 2013-2016년 데이터만 추출\n",
    "df1 = df1[(df1['사고연도'] >= 2014) & (df1['사고연도'] <= 2016)]\n",
    "\n",
    "drop_list1 = ['사고연도', '사고유형구분', '데이터기준일자', '제공기관코드', '제공기관명']\n",
    "df1 = df1.drop(columns=drop_list1)\n",
    "\n",
    "df2 = pd.read_csv('data/교통사고 데이터/전국교통사고다발지역(2017-2023).csv', encoding='euc-kr')\n",
    "drop_list2 = ['법정동코드']\n",
    "df2 = df2.drop(columns=drop_list2)\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "# '위치코드'의 앞 5자리 숫자로 그룹화하고 사고건수를 합산\n",
    "df['위치코드_시군구'] = df['위치코드'].astype(str).str[:5]\n",
    "\n",
    "# 그룹화하고 첫 번째 '사고지역위치명'의 처음 두 단어를 사용\n",
    "df_grouped = df.groupby('위치코드_시군구', as_index=False).agg({\n",
    "    '사고건수': 'sum',\n",
    "    '사고지역위치명': lambda x: ' '.join(x.iloc[0].split()[:2])  # 첫 번째 위치명에서 처음 두 단어 추출\n",
    "})\n",
    "df_grouped = df_grouped.rename(columns={'사고지역위치명': '시군구명'})\n",
    "\n",
    "# 결과를 JSON 파일로 저장\n",
    "df_grouped.to_json('data/accident_data.json', orient='records', force_ascii=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    위치코드_시군구  사고건수          시군구명\n",
      "46     11560  1601    서울특별시 영등포구\n",
      "51     11710  1517     서울특별시 송파구\n",
      "188    27290  1412     대구광역시 달서구\n",
      "22     11230  1399    서울특별시 동대문구\n",
      "216    30170  1393      대전광역시 서구\n",
      "..       ...   ...           ...\n",
      "128    20234     4      경상남도 창원시\n",
      "67     13074     4       경기도 파주시\n",
      "66     13064     4      경기도 의정부시\n",
      "207    28720     4     인천광역시 옹진군\n",
      "133    21035     3  제주특별자치도 서귀포시\n",
      "\n",
      "[447 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df_grouped.sort_values('사고건수', ascending=False)\n",
    "\n",
    "# 결과를 JSON 파일로 저장 (표2 표시용)\n",
    "df_sorted.head(10).to_json('data/top10_accident_grouped.json', orient='records', force_ascii=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 주소명을 통일하는 함수\n",
    "def standardize_address(address):\n",
    "    address = re.sub(r'강원 ', '강원도 ', address)\n",
    "    address = re.sub(r'경북 ', '경상북도 ', address)\n",
    "    address = re.sub(r'광주 ', '광주광역시 ', address)\n",
    "    address = re.sub(r'대구 ', '대구광역시 ', address)\n",
    "    address = re.sub(r'인천 ', '인천광역시 ', address)\n",
    "    address = re.sub(r'전북 ', '전라북도 ', address)\n",
    "    address = re.sub(r'충남 ', '충청남도 ', address)\n",
    "    # 필요에 따라 다른 표준화 작업 추가 가능\n",
    "    return address.strip()\n",
    "\n",
    "# 표준화된 주소명을 만들기\n",
    "df['사고지역위치명'] = df['사고지역위치명'].apply(standardize_address)\n",
    "\n",
    "# 위치명으로 그룹화하고 사고건수를 합산\n",
    "df_grouped_1 = df.groupby('사고지역위치명', as_index=False).agg({\n",
    "    '사고건수': 'sum'\n",
    "})\n",
    "\n",
    "# 사고건수 기준으로 내림차순 정렬\n",
    "df_sorted_1 = df_grouped_1.sort_values('사고건수', ascending=False)\n",
    "\n",
    "# 결과를 JSON 파일로 저장 (표1 표시용)\n",
    "df_sorted_1.head(10).to_json('data/top10_accident_locations.json', orient='records', force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '사고지역위치명'에서 처음 두 단어 추출 함수\n",
    "def extract_first_two_words(location):\n",
    "    return ' '.join(location.split()[:2])\n",
    "\n",
    "# 처음 두 단어로 새로운 열 생성\n",
    "df['시군구명'] = df['사고지역위치명'].apply(extract_first_two_words)\n",
    "\n",
    "# '시군구명'로 그룹화하고 사고건수를 합산\n",
    "df_grouped_2 = df.groupby('시군구명', as_index=False).agg({\n",
    "    '사고건수': 'sum'\n",
    "})\n",
    "\n",
    "# df_sorted_2 = df_grouped_2.sort_values('사고건수', ascending=False)\n",
    "\n",
    "# # 결과를 JSON 파일로 저장 (표2 표시용)\n",
    "# df_sorted_2.head(10).to_json('data/top10_accident_grouped.json', orient='records', force_ascii=False)\n",
    "\n",
    "# # 결과 출력\n",
    "# print(df_sorted_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일이 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# '시군구명'에서 시도 이름 추출 함수\n",
    "def extract_city_name(region_name):\n",
    "    return region_name.split()[0]\n",
    "\n",
    "# 시도 이름으로 새로운 열 생성\n",
    "df['시도명'] = df['시군구명'].apply(extract_city_name)\n",
    "\n",
    "# 시도명으로 그룹화하고 사고건수를 합산\n",
    "df_grouped = df.groupby('시도명', as_index=False).agg({\n",
    "    '사고건수': 'sum'\n",
    "})\n",
    "\n",
    "# 각 시도별로 데이터를 분류하여 JSON 파일로 저장\n",
    "city_data = {}\n",
    "for _, row in df_grouped.iterrows():\n",
    "    city_name = row['시도명']\n",
    "    accident_count = row['사고건수']\n",
    "    city_data[city_name] = accident_count\n",
    "\n",
    "    # 파일 저장 경로 설정\n",
    "    file_name = f'data/시도별json/{city_name}_accident_data.json'\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        json.dump({city_name: accident_count}, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"JSON 파일이 성공적으로 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    도시명  사고건수\n",
      "0   강릉시   352\n",
      "1   고성군    98\n",
      "2   동해시   243\n",
      "3   삼척시   222\n",
      "4   속초시   349\n",
      "5   양구군    78\n",
      "6   양양군   115\n",
      "7   영월군   124\n",
      "8   원주시   914\n",
      "9   인제군    74\n",
      "10  정선군    93\n",
      "11  철원군    94\n",
      "12  춘천시   442\n",
      "13  태백시   192\n",
      "14  평창군   102\n",
      "15  홍천군   107\n",
      "16  화천군    43\n",
      "17  횡성군   152\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 데이터를 DataFrame으로 변환\n",
    "df1 = pd.read_json('data/시도별 json 파일/강원_accident_data.json')\n",
    "df2 = pd.read_json('data/시도별 json 파일/강원도_accident_data.json')\n",
    "\n",
    "# 두 DataFrame을 결합\n",
    "combined_df = pd.concat([df1, df2])\n",
    "\n",
    "# '시군구명' 컬럼에서 도시 이름 추출 및 사고건수 집계\n",
    "combined_df['도시명'] = combined_df['시군구명'].apply(lambda x: x.split(' ')[1])\n",
    "result_df = combined_df.groupby('도시명')['사고건수'].sum().reset_index()\n",
    "\n",
    "# 결과 DataFrame을 JSON 파일로 내보내기\n",
    "result_df.to_json('data/시도별 json 파일/강원도_accidents.json', orient='records', force_ascii=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    도시명  사고건수\n",
      "0   경산시   475\n",
      "1   경주시   530\n",
      "2   고령군   100\n",
      "3   구미시   500\n",
      "4   군위군    30\n",
      "5   김천시   360\n",
      "6   문경시   218\n",
      "7   봉화군    58\n",
      "8   상주시   314\n",
      "9   성주군   173\n",
      "10  안동시   483\n",
      "11  영덕군   177\n",
      "12  영양군    96\n",
      "13  영주시   369\n",
      "14  영천시   265\n",
      "15  예천군   127\n",
      "16  울릉군     8\n",
      "17  울진군    40\n",
      "18  의성군   130\n",
      "19  청도군   121\n",
      "20  청송군    36\n",
      "21  칠곡군   309\n",
      "22  포항시   748\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 데이터를 DataFrame으로 변환\n",
    "df1 = pd.read_json('data/시도별 json 파일/경북_accident_data.json')\n",
    "df2 = pd.read_json('data/시도별 json 파일/경상북도_accident_data.json')\n",
    "\n",
    "# 두 DataFrame을 결합\n",
    "combined_df = pd.concat([df1, df2])\n",
    "\n",
    "# '시군구명' 컬럼에서 도시 이름 추출 및 사고건수 집계\n",
    "combined_df['도시명'] = combined_df['시군구명'].apply(lambda x: x.split(' ')[1])\n",
    "result_df = combined_df.groupby('도시명')['사고건수'].sum().reset_index()\n",
    "\n",
    "# 결과 DataFrame을 JSON 파일로 내보내기\n",
    "result_df.to_json('data/시도별 json 파일/경상북도_accidents.json', orient='records', force_ascii=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    도시명  사고건수\n",
      "0   계룡시    64\n",
      "1   공주시   276\n",
      "2   금산군   119\n",
      "3   논산시   235\n",
      "4   당진시   316\n",
      "5   보령시   296\n",
      "6   부여군   144\n",
      "7   서산시   340\n",
      "8   서천군   178\n",
      "9   아산시   457\n",
      "10  예산군   149\n",
      "11  천안시   893\n",
      "12  청양군    94\n",
      "13  태안군   172\n",
      "14  홍성군   201\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 데이터를 DataFrame으로 변환\n",
    "df1 = pd.read_json('data/시도별 json 파일/충청남도_accident_data.json')\n",
    "df2 = pd.read_json('data/시도별 json 파일/충남_accident_data.json')\n",
    "\n",
    "# 두 DataFrame을 결합\n",
    "combined_df = pd.concat([df1, df2])\n",
    "\n",
    "# '시군구명' 컬럼에서 도시 이름 추출 및 사고건수 집계\n",
    "combined_df['도시명'] = combined_df['시군구명'].apply(lambda x: x.split(' ')[1])\n",
    "result_df = combined_df.groupby('도시명')['사고건수'].sum().reset_index()\n",
    "\n",
    "# 결과 DataFrame을 JSON 파일로 내보내기\n",
    "result_df.to_json('data/시도별 json 파일/충청남도_accidents.json', orient='records', force_ascii=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     도시명  사고건수\n",
      "0    강남구  1219\n",
      "1    강동구  1037\n",
      "2    강북구  1419\n",
      "3    강서구  1073\n",
      "4    관악구  1352\n",
      "5    광진구   896\n",
      "6    구로구  1086\n",
      "7    금천구   816\n",
      "8    노원구  1064\n",
      "9    도봉구   740\n",
      "10  동대문구  1421\n",
      "11   동작구  1091\n",
      "12   마포구   982\n",
      "13  서대문구   768\n",
      "14   서초구  1117\n",
      "15   성동구   930\n",
      "16   성북구  1312\n",
      "17   송파구  1536\n",
      "18   양천구  1056\n",
      "19  영등포구  1683\n",
      "20   용산구   805\n",
      "21   은평구   994\n",
      "22   종로구   966\n",
      "23    중구   990\n",
      "24   중랑구  1118\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 DataFrame으로 변환\n",
    "combined_df = pd.read_json('data/시도별 json 파일/서울특별시_accidents.json')\n",
    "\n",
    "# '시군구명' 컬럼에서 도시 이름 추출 및 사고건수 집계\n",
    "combined_df['도시명'] = combined_df['시군구명'].apply(lambda x: x.split(' ')[1])\n",
    "result_df = combined_df.groupby('도시명')['사고건수'].sum().reset_index()\n",
    "\n",
    "# 결과 DataFrame을 JSON 파일로 내보내기\n",
    "result_df.to_json('data/시도별 json 파일/서울_accidents.json', orient='records', force_ascii=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 연도의 데이터를 결합하기 위해 파일 경로 목록을 만듭니다.\n",
    "file_paths = [\n",
    "    'data/교통사고 데이터/도로교통공단_일자별 시군구별 교통사고 건수(2016).csv',\n",
    "    'data/교통사고 데이터/도로교통공단_일자별 시군구별 교통사고 건수(2017).csv',\n",
    "    'data/교통사고 데이터/도로교통공단_일자별 시군구별 교통사고 건수(2018).csv',\n",
    "    'data/교통사고 데이터/도로교통공단_일자별 시군구별 교통사고 건수(2019).csv',\n",
    "    'data/교통사고 데이터/도로교통공단_일자별 시군구별 교통사고 건수(2020).csv',\n",
    "    'data/교통사고 데이터/도로교통공단_일자별 시군구별 교통사고 건수(2021).csv',\n",
    "    'data/교통사고 데이터/도로교통공단_일자별 시군구별 교통사고 건수(2022).csv',\n",
    "    'data/교통사고 데이터/도로교통공단_일자별 시군구별 교통사고 건수(2023).csv'\n",
    "]\n",
    "\n",
    "# 데이터를 저장할 빈 리스트를 만듭니다.\n",
    "df3_list = []\n",
    "\n",
    "# 각 파일을 불러와서 리스트에 추가합니다.\n",
    "for file_path in file_paths:\n",
    "    year = int(file_path[-9:-5])  # 파일명에서 연도 추출\n",
    "    df3 = pd.read_csv(file_path, encoding='euc-kr')\n",
    "    df3['발생년도'] = year  # 발생년도 열 추가\n",
    "    df3_list.append(df3)\n",
    "\n",
    "# 모든 데이터를 하나의 데이터프레임으로 결합합니다.\n",
    "df3_combined = pd.concat(df3_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 어린이날 교통사고 추이 분석\n",
    "# ----------------------------\n",
    "\n",
    "# 어린이날 (5월 5일) 데이터 필터링\n",
    "df_children_day = df3_combined[(df3_combined['발생월'] == 5) & (df3_combined['발생일'] == 5)]\n",
    "\n",
    "# 연도별 사고 건수 및 사망자수, 중상자수, 경상자수 집계\n",
    "children_day_stats = df_children_day.groupby('발생년도').sum()[['사고건수', '사망자수', '중상자수', '경상자수']].reset_index()\n",
    "\n",
    "children_day_stats.to_json('data/55_accident.json', orient='records', force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      발생월  발생일  시도   시군구  사고건수  사망자수  중상자수  경상자수  부상신고자수  발생년도 휴일명  \\\n",
      "0       2    7  서울   용산구     3     0     1     2       0  2016  설날   \n",
      "1       2    7  서울  동대문구     4     0     1     3       0  2016  설날   \n",
      "2       2    7  서울   성북구     1     0     0     0       1  2016  설날   \n",
      "3       2    7  서울   도봉구     2     0     1     1       0  2016  설날   \n",
      "4       2    7  서울   은평구     2     0     1     1       0  2016  설날   \n",
      "...   ...  ...  ..   ...   ...   ...   ...   ...     ...   ...  ..   \n",
      "4603    1   24  대전   대덕구     1     0     0     1       0  2023  설날   \n",
      "4604    1   24  울산    중구     1     0     1     0       0  2023  설날   \n",
      "4605    1   24  울산    남구     3     0     2     1       0  2023  설날   \n",
      "4606    1   24  울산    북구     1     0     1     0       0  2023  설날   \n",
      "4607    1   24  울산   울주군     3     0     1     5       0  2023  설날   \n",
      "\n",
      "             휴일기간  \n",
      "0     02/07~02/10  \n",
      "1     02/07~02/10  \n",
      "2     02/07~02/10  \n",
      "3     02/07~02/10  \n",
      "4     02/07~02/10  \n",
      "...           ...  \n",
      "4603  01/21~01/24  \n",
      "4604  01/21~01/24  \n",
      "4605  01/21~01/24  \n",
      "4606  01/21~01/24  \n",
      "4607  01/21~01/24  \n",
      "\n",
      "[4608 rows x 12 columns]\n",
      "      발생월  발생일  시도   시군구  사고건수  사망자수  중상자수  경상자수  부상신고자수  발생년도 휴일명  \\\n",
      "0       9   14  서울   종로구     3     0     1     2       0  2016  추석   \n",
      "1       9   14  서울   용산구     7     0     1     8       2  2016  추석   \n",
      "2       9   14  서울   성동구     2     0     1     3       0  2016  추석   \n",
      "3       9   14  서울  동대문구     2     0     0     2       0  2016  추석   \n",
      "4       9   14  서울   성북구     2     0     1     1       0  2016  추석   \n",
      "...   ...  ...  ..   ...   ...   ...   ...   ...     ...   ...  ..   \n",
      "4405    9   30  대전   유성구     2     0     0     4       0  2023  추석   \n",
      "4406    9   30  대전   대덕구     2     0     1     1       0  2023  추석   \n",
      "4407    9   30  울산    중구     2     0     0     5       0  2023  추석   \n",
      "4408    9   30  울산    북구     2     0     1     3       0  2023  추석   \n",
      "4409    9   30  세종   세종시     1     0     0     1       0  2023  추석   \n",
      "\n",
      "             휴일기간  \n",
      "0     09/14~09/16  \n",
      "1     09/14~09/16  \n",
      "2     09/14~09/16  \n",
      "3     09/14~09/16  \n",
      "4     09/14~09/16  \n",
      "...           ...  \n",
      "4405  09/28~09/30  \n",
      "4406  09/28~09/30  \n",
      "4407  09/28~09/30  \n",
      "4408  09/28~09/30  \n",
      "4409  09/28~09/30  \n",
      "\n",
      "[4410 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# 연도별 설날 연휴 날짜 딕셔너리\n",
    "lunar_new_year_dates = {\n",
    "    2016: [('02-07'), ('02-08'), ('02-09'), ('02-10')],\n",
    "    2017: [('01-27'), ('01-28'), ('01-29'), ('01-30')],\n",
    "    2018: [('02-15'), ('02-16'), ('02-17'), ('02-18')],\n",
    "    2019: [('02-02'), ('02-03'), ('02-04'), ('02-05'), ('02-06')],\n",
    "    2020: [('01-24'), ('01-25'), ('01-26'), ('01-27')],\n",
    "    2021: [('02-11'), ('02-12'), ('02-13'), ('02-14')],\n",
    "    2022: [('01-31'), ('02-01'), ('02-02')],\n",
    "    2023: [('01-21'), ('01-22'), ('01-23'), ('01-24')]\n",
    "}\n",
    "\n",
    "# 연도별 추석 연휴 날짜 딕셔너리\n",
    "chuseok_dates = {\n",
    "    2016: [('09-14'), ('09-15'), ('09-16')],\n",
    "    2017: [('10-03'), ('10-04'), ('10-05'), ('10-06')],\n",
    "    2018: [('09-23'), ('09-24'), ('09-25'), ('09-26')],\n",
    "    2019: [('09-12'), ('09-13'), ('09-14')],\n",
    "    2020: [('09-30'), ('10-01'), ('10-02'), ('10-03')],\n",
    "    2021: [('09-20'), ('09-21'), ('09-22')],\n",
    "    2022: [('09-09'), ('09-10'), ('09-11'), ('09-12')],\n",
    "    2023: [('09-28'), ('09-29'), ('09-30')]\n",
    "}\n",
    "\n",
    "def filter_holiday_data(df, holiday_dates, holiday_name):\n",
    "    holiday_data_list = []\n",
    "    for year, dates in holiday_dates.items():\n",
    "        # 휴일 기간 계산\n",
    "        start_date = dates[0].replace('-', '/')\n",
    "        end_date = dates[-1].replace('-', '/')\n",
    "        holiday_period = f\"{start_date}~{end_date}\"\n",
    "        \n",
    "        for date_str in dates:\n",
    "            month, day = map(int, date_str.split('-'))\n",
    "            filtered_data = df[\n",
    "                (df['발생년도'] == year) &\n",
    "                (df['발생월'] == month) &\n",
    "                (df['발생일'] == day)\n",
    "            ].copy()  # 데이터프레임의 복사본을 생성하여 열을 추가함\n",
    "            filtered_data['휴일명'] = holiday_name\n",
    "            filtered_data['휴일기간'] = holiday_period  # 휴일 기간을 추가\n",
    "            holiday_data_list.append(filtered_data)\n",
    "    return pd.concat(holiday_data_list, ignore_index=True)\n",
    "\n",
    "# 설날 교통사고 데이터 필터링 및 집계\n",
    "df_lunar_new_year = filter_holiday_data(df3_combined, lunar_new_year_dates, '설날')\n",
    "lunar_new_year_stats = df_lunar_new_year.groupby('발생년도').sum()[['사고건수', '사망자수', '중상자수', '경상자수']].reset_index()\n",
    "\n",
    "# 추석 교통사고 데이터 필터링 및 집계\n",
    "df_chuseok = filter_holiday_data(df3_combined, chuseok_dates, '추석')\n",
    "chuseok_stats = df_chuseok.groupby('발생년도').sum()[['사고건수', '사망자수', '중상자수', '경상자수']].reset_index()\n",
    "\n",
    "df_lunar_new_year.to_json(\"data/luner_new_year_accident.json\", orient='records', force_ascii=False)\n",
    "df_chuseok.to_json(\"data/chuseok_accident.json\", orient='records', force_ascii=False)\n",
    "\n",
    "# 추가된 휴일명 및 휴일기간 열을 포함한 데이터프레임 확인\n",
    "print(df_lunar_new_year)\n",
    "print(df_chuseok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 월드컵 기간 설정 (예시로 대한민국 경기 날짜 포함)\n",
    "world_cup_dates_2018 = [\n",
    "    ('06-14', '07-15')  # 2018 러시아 월드컵 전체 기간\n",
    "]\n",
    "\n",
    "world_cup_dates_2022 = [\n",
    "    ('11-20', '12-18')  # 2022 카타르 월드컵 전체 기간\n",
    "]\n",
    "\n",
    "def filter_world_cup_data(df, world_cup_dates, year):\n",
    "    world_cup_data_list = []\n",
    "    for start_date, end_date in world_cup_dates:\n",
    "        start_month, start_day = map(int, start_date.split('-'))\n",
    "        end_month, end_day = map(int, end_date.split('-'))\n",
    "        \n",
    "        filtered_data = df[\n",
    "            (df['발생년도'] == year) &\n",
    "            ((df['발생월'] == start_month) & (df['발생일'] >= start_day) | (df['발생월'] == end_month) & (df['발생일'] <= end_day))\n",
    "        ]\n",
    "        world_cup_data_list.append(filtered_data)\n",
    "    \n",
    "    return pd.concat(world_cup_data_list, ignore_index=True)\n",
    "\n",
    "# 2018년 데이터 필터링\n",
    "df_wc_2018 = filter_world_cup_data(df3_combined, world_cup_dates_2018, 2018)\n",
    "\n",
    "# 2022년 데이터 필터링\n",
    "df_wc_2022 = filter_world_cup_data(df3_combined, world_cup_dates_2022, 2022)\n",
    "\n",
    "# 연도별 사고 건수 집계\n",
    "wc_2018_stats = df_wc_2018.groupby('발생년도').sum()[['사고건수']].reset_index()\n",
    "wc_2022_stats = df_wc_2022.groupby('발생년도').sum()[['사고건수']].reset_index()\n",
    "\n",
    "# 두 기간의 데이터 병합\n",
    "wc_stats_combined = pd.concat([wc_2018_stats, wc_2022_stats], ignore_index=True)\n",
    "\n",
    "wc_stats_combined.to_json(\"data/worldcup.json\", orient='records', force_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
